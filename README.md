I completed a computer vision project using the EPIC-KITCHENS-100 dataset, where I extracted RGB video frames, processed large sequence files, and aligned them with the official action annotations. I built a Python pipeline that matched each frame to its corresponding verb and noun labels using start/stop timestamps and frame indices. This resulted in a fully structured, frame-level dataset ready for training action recognition models.
